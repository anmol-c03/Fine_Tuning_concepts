{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5457fe6c-6f0b-4e12-a244-3d5e93e6e8a5",
   "metadata": {},
   "source": [
    "# This notebook is the implementation of \n",
    "https://arxiv.org/pdf/2402.17764\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a3ed897-a9a1-4f41-9efc-42ecce17f62e",
   "metadata": {},
   "source": [
    "'''\n",
    "points to remember\n",
    "1.every bit in LLM is represented by tenerary bits {1,0,-1}\n",
    "2.perplexity is comparable to other higher bit LLMs\n",
    "3.presence of zero enhances feature extraction\n",
    "4.less hadrware req,latency \n",
    "\n",
    "Though title is 'The Era of 1-bit LLMs' but the model name is BitNet b1.58 \n",
    "because 1.58 bits are required to represent 3 number i.e. -1,0,1\n",
    "log2(3)=1.58\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f96f56e0-6146-4b96-be43-36ca7e50f2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(3289)\n",
    "w=torch.randn(32,200) # hidden neuron 200\n",
    "embeddings=torch.randn(8,32) # batch size 8 with d_model 32\n",
    "y=embeddings@w\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ebb725f-a69a-42bf-ae1a-8de9cb420bdb",
   "metadata": {},
   "source": [
    "now assuming y be the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a3d95b9-8f12-418a-be8f-6bd1a5ca59cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1.,  1.,  ..., -1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  ..., -1., -1.,  1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "        ...,\n",
      "        [-1., -0., -1.,  ...,  1.,  1.,  1.],\n",
      "        [-1., -1., -1.,  ..., -1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.]])\n",
      "time_taken 0.17141413688659668\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def round_clip(xs):\n",
    "    x=xs/torch.mean(xs)\n",
    "    x=x.view(-1)\n",
    "    out=torch.zeros(x.shape)\n",
    "    out=torch.clamp(torch.round(x),-1,1)\n",
    "    return out\n",
    "    \n",
    "for _ in range(10000):\n",
    "    c=round_clip(y.view(1,-1))\n",
    "    # c=round_clip(y.view(1,-1))\n",
    "    # c=round_clip(y.view(1,-1))\n",
    "    # c=round_clip(y.view(1,-1))\n",
    "print(c.view(y.shape))\n",
    "print('time_taken',time.time()-start_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fb204ee-b240-4a9c-9fd1-fa0369ad405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0024, -0.0011, -0.0004,  ...,  0.0007,  0.0004, -0.0005],\n",
      "        [-0.0006,  0.0006,  0.0007,  ..., -0.0017, -0.0015, -0.0002],\n",
      "        [ 0.0004,  0.0007, -0.0006,  ...,  0.0007, -0.0007,  0.0007],\n",
      "        ...,\n",
      "        [ 0.0008, -0.0012,  0.0011,  ...,  0.0015, -0.0014, -0.0018],\n",
      "        [ 0.0006,  0.0002,  0.0020,  ..., -0.0010,  0.0007,  0.0007],\n",
      "        [ 0.0004, -0.0008, -0.0006,  ..., -0.0016, -0.0015,  0.0013]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from bitnet import BitLinear\n",
    "\n",
    "# Input\n",
    "x = torch.randn(10, 512)\n",
    "\n",
    "# BitLinear layer\n",
    "layer = BitLinear(512, 400)\n",
    "\n",
    "# Output\n",
    "y = layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b592d-62e9-48db-a2e1-ecd107187561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
